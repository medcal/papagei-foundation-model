#!/usr/bin/env python3
"""
ä¿®æ­£çš„VitalDBæ¨¡å‹è¯„ä¼°è„šæœ¬
è®¡ç®—MAEã€RMSEç­‰è¯¦ç»†æ€§èƒ½æŒ‡æ ‡
"""

import pandas as pd
import numpy as np
import os
import torch
import joblib
from models.resnet import ResNet1DMoE
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
from torchvision import transforms
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


class VitalDBPPGDataset(Dataset):
    """VitalDB PPGæ•°æ®é›† - æ”¯æŒ.npyæ–‡ä»¶æ ¼å¼"""

    def __init__(self, df, signal_dir, fs_target=125, transform=None):
        self.df = df.reset_index(drop=True)
        self.signal_dir = signal_dir
        self.fs_target = fs_target
        self.transform = transform

        print(f"ğŸ“Š æ•°æ®é›†åˆå§‹åŒ–:")
        print(f"   - æ ·æœ¬æ•°: {len(self.df)}")
        print(f"   - ä¿¡å·ç›®å½•: {signal_dir}")
        print(f"   - ç›®æ ‡é‡‡æ ·ç‡: {fs_target}Hz")

        # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
        missing_files = []
        for idx, row in self.df.iterrows():
            signal_path = os.path.join(signal_dir, row['segments'])
            if not os.path.exists(signal_path):
                missing_files.append(row['segments'])

        if missing_files:
            print(f"âš ï¸ ç¼ºå¤± {len(missing_files)} ä¸ªä¿¡å·æ–‡ä»¶")
            # ç§»é™¤ç¼ºå¤±æ–‡ä»¶çš„è®°å½•
            self.df = self.df[~self.df['segments'].isin(missing_files)].reset_index(drop=True)
            print(f"   æ¸…ç†åæ ·æœ¬æ•°: {len(self.df)}")

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        # åŠ è½½ä¿¡å·
        signal = self.load_signal(idx)

        # è·å–æ ‡ç­¾
        row = self.df.iloc[idx]
        svri = float(row['svri'])
        skewness = float(row['skewness'])
        ipa = float(row['ipa'])

        # åº”ç”¨å˜æ¢
        if self.transform:
            signal = self.transform(signal)

        # ç¡®ä¿ä¿¡å·æ˜¯æ­£ç¡®çš„å½¢çŠ¶ [1, length]
        if signal.ndim == 1:
            signal = signal[np.newaxis, :]  # æ·»åŠ é€šé“ç»´åº¦

        # è½¬æ¢ä¸ºå¼ é‡
        signal = torch.FloatTensor(signal)
        labels = torch.FloatTensor([svri, skewness, ipa])

        return signal, labels

    def load_signal(self, idx):
        """åŠ è½½ä¿¡å·æ–‡ä»¶"""
        row = self.df.iloc[idx]
        signal_path = os.path.join(self.signal_dir, row['segments'])

        try:
            # åŠ è½½.npyæ–‡ä»¶
            signal = np.load(signal_path)

            # ç¡®ä¿ä¿¡å·é•¿åº¦æ­£ç¡®
            target_length = 1250  # 10ç§’ * 125Hz
            if len(signal) != target_length:
                # é‡é‡‡æ ·åˆ°ç›®æ ‡é•¿åº¦
                from scipy.signal import resample
                signal = resample(signal, target_length)

            # æ£€æŸ¥ä¿¡å·è´¨é‡
            if not np.all(np.isfinite(signal)):
                print(f"âš ï¸ ä¿¡å·åŒ…å«æ— æ•ˆå€¼: {signal_path}")
                signal = np.nan_to_num(signal)

            return signal.astype(np.float32)

        except Exception as e:
            print(f"âŒ åŠ è½½ä¿¡å·å¤±è´¥: {signal_path}, é”™è¯¯: {e}")
            # è¿”å›é›¶ä¿¡å·ä½œä¸ºå¤‡é€‰
            return np.zeros(1250, dtype=np.float32)


def load_trained_model(model_path, model_config, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {model_path}")

    try:
        model = ResNet1DMoE(
            in_channels=1,
            base_filters=model_config['base_filters'],
            kernel_size=model_config['kernel_size'],
            stride=model_config['stride'],
            groups=model_config['groups'],
            n_block=model_config['n_block'],
            n_classes=model_config['n_classes'],
            n_experts=model_config['n_experts']
        )

        # åŠ è½½æ¨¡å‹æƒé‡
        state_dict = torch.load(model_path, map_location=device)
        model.load_state_dict(state_dict)
        model.to(device)
        model.eval()

        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model

    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None


def evaluate_model(model, dataloader, device):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    print("ğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°...")

    model.eval()

    all_predictions = {'svri': [], 'ipa': [], 'sqi': []}
    all_targets = {'svri': [], 'ipa': [], 'sqi': []}
    embeddings_list = []

    with torch.no_grad():
        for batch_idx, (X, y) in enumerate(tqdm(dataloader, desc="è¯„ä¼°è¿›åº¦")):
            signal = X.to(device)
            svri_target = y[:, 0].to(device)
            sqi_target = y[:, 1].to(device)  # skewnessä½œä¸ºsqi
            ipa_target = y[:, 2].to(device)

            try:
                # æ¨¡å‹é¢„æµ‹
                embeddings, ipa_pred, sqi_pred, _ = model(signal)

                # æ”¶é›†é¢„æµ‹å’ŒçœŸå®å€¼
                all_predictions['ipa'].extend(ipa_pred.cpu().numpy().flatten())
                all_predictions['sqi'].extend(sqi_pred.cpu().numpy().flatten())
                all_targets['svri'].extend(svri_target.cpu().numpy())
                all_targets['ipa'].extend(ipa_target.cpu().numpy())
                all_targets['sqi'].extend(sqi_target.cpu().numpy())
                embeddings_list.extend(embeddings.cpu().numpy())

            except Exception as e:
                print(f"âš ï¸ æ‰¹æ¬¡ {batch_idx} é¢„æµ‹å¤±è´¥: {e}")
                continue

    return all_predictions, all_targets, np.array(embeddings_list)


def calculate_metrics(predictions, targets, metric_name):
    """è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡"""
    print(f"\nğŸ“ˆ {metric_name} æ€§èƒ½æŒ‡æ ‡:")

    pred = np.array(predictions)
    true = np.array(targets)

    if len(pred) == 0 or len(true) == 0:
        print(f"âŒ æ²¡æœ‰æœ‰æ•ˆçš„é¢„æµ‹æ•°æ®")
        return {'mae': 0, 'rmse': 0, 'r2': 0, 'mape': 0}

    # è®¡ç®—æŒ‡æ ‡
    mae = mean_absolute_error(true, pred)
    rmse = np.sqrt(mean_squared_error(true, pred))
    r2 = r2_score(true, pred)

    # é¿å…é™¤é›¶é”™è¯¯
    non_zero_mask = np.abs(true) > 1e-8
    if np.sum(non_zero_mask) > 0:
        mape = np.mean(np.abs((true[non_zero_mask] - pred[non_zero_mask]) / true[non_zero_mask])) * 100
    else:
        mape = 0

    print(f"   MAE:  {mae:.4f}")
    print(f"   RMSE: {rmse:.4f}")
    print(f"   RÂ²:   {r2:.4f}")
    print(f"   MAPE: {mape:.2f}%")

    return {'mae': mae, 'rmse': rmse, 'r2': r2, 'mape': mape}


def plot_predictions(predictions, targets, metric_name, save_path):
    """ç»˜åˆ¶é¢„æµ‹vsçœŸå®å€¼æ•£ç‚¹å›¾"""
    pred = np.array(predictions)
    true = np.array(targets)

    if len(pred) == 0 or len(true) == 0:
        print(f"âš ï¸ æ²¡æœ‰æ•°æ®ç”¨äºç»˜åˆ¶ {metric_name} å›¾è¡¨")
        return

    plt.figure(figsize=(8, 6))
    plt.scatter(true, pred, alpha=0.6, s=30)

    # æ·»åŠ å®Œç¾é¢„æµ‹çº¿
    min_val = min(true.min(), pred.min())
    max_val = max(true.max(), pred.max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='å®Œç¾é¢„æµ‹')

    plt.xlabel(f'çœŸå® {metric_name}')
    plt.ylabel(f'é¢„æµ‹ {metric_name}')
    plt.title(f'{metric_name} é¢„æµ‹æ€§èƒ½')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # æ·»åŠ RÂ²ä¿¡æ¯
    r2 = r2_score(true, pred)
    plt.text(0.05, 0.95, f'RÂ² = {r2:.4f}', transform=plt.gca().transAxes,
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   ğŸ“Š å›¾è¡¨å·²ä¿å­˜: {save_path}")


def main():
    print("ğŸš€ ä¿®æ­£çš„VitalDBæ¨¡å‹è¯„ä¼°")
    print("=" * 50)

    # æŸ¥æ‰¾æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶
    models_dir = "models"
    if not os.path.exists(models_dir):
        print("âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
        return

    # è·å–æœ€æ–°çš„æ¨¡å‹ç›®å½•
    model_dirs = []
    for d in os.listdir(models_dir):
        dir_path = os.path.join(models_dir, d)
        if os.path.isdir(dir_path) and not d.startswith('__') and not d.startswith('.'):
            model_dirs.append(d)

    if not model_dirs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ¨¡å‹ç›®å½•")
        print("å¯ç”¨ç›®å½•:")
        for item in os.listdir(models_dir):
            print(f"   - {item}")
        return

    latest_dir = sorted(model_dirs)[-1]
    model_dir_path = os.path.join(models_dir, latest_dir)

    print(f"ğŸ” ä½¿ç”¨æ¨¡å‹ç›®å½•: {latest_dir}")

    # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹æ–‡ä»¶
    model_files = [f for f in os.listdir(model_dir_path) if f.endswith('.pt')]
    if not model_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
        print("ç›®å½•å†…å®¹:")
        for item in os.listdir(model_dir_path):
            print(f"   - {item}")
        return

    # ä¼˜å…ˆé€‰æ‹©bestæ¨¡å‹
    best_files = [f for f in model_files if 'best' in f]
    if best_files:
        model_file = best_files[0]
    else:
        model_file = sorted(model_files)[-1]

    model_path = os.path.join(model_dir_path, model_file)
    print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {model_file}")

    # è®¾å¤‡é…ç½®
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")

    # æ¨¡å‹é…ç½®ï¼ˆéœ€è¦ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    model_config = {
        'base_filters': 16,
        'kernel_size': 3,
        'stride': 2,
        'groups': 1,
        'n_block': 12,
        'n_classes': 256,
        'n_experts': 2
    }

    # åŠ è½½æ¨¡å‹
    model = load_trained_model(model_path, model_config, device)
    if model is None:
        return

    # å‡†å¤‡æ•°æ®
    print("ğŸ“Š å‡†å¤‡è¯„ä¼°æ•°æ®...")
    try:
        # åŠ è½½æ•°æ®
        data_file = "../data/vital/train_clean.csv"
        signal_dir = "../data/vitaldbppg"

        if not os.path.exists(data_file):
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
            return

        if not os.path.exists(signal_dir):
            print(f"âŒ ä¿¡å·ç›®å½•ä¸å­˜åœ¨: {signal_dir}")
            return

        df = pd.read_csv(data_file)
        print(f"âœ… åŠ è½½æ•°æ®æ–‡ä»¶: {len(df)} ä¸ªæ ·æœ¬")

        # æ•°æ®è¿‡æ»¤
        original_len = len(df)
        df = df[(df['svri'] > 0) & (df['svri'] < 2)]
        df = df[(df['ipa'] > -10) & (df['ipa'] < 10)]
        df = df[(df['skewness'] > -3) & (df['skewness'] < 3)]

        print(f"âœ… æ•°æ®è¿‡æ»¤å®Œæˆ: {len(df)} ä¸ªæœ‰æ•ˆæ ·æœ¬ (è¿‡æ»¤æ‰ {original_len - len(df)} ä¸ª)")

        if len(df) == 0:
            print("âŒ è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆæ•°æ®")
            return

    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    # åˆ›å»ºæ•°æ®é›†
    try:
        dataset = VitalDBPPGDataset(
            df=df,
            signal_dir=signal_dir,
            fs_target=125,
            transform=None  # è¯„ä¼°æ—¶ä¸ä½¿ç”¨æ•°æ®å¢å¼º
        )

        if len(dataset) == 0:
            print("âŒ æ•°æ®é›†ä¸ºç©º")
            return

        eval_dataloader = DataLoader(
            dataset=dataset,
            batch_size=8,  # å‡å°æ‰¹æ¬¡å¤§å°
            shuffle=False,
            num_workers=0,
            drop_last=False
        )

        print(f"âœ… è¯„ä¼°æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸï¼Œæ•°æ®é›†å¤§å°: {len(dataset)}")

    except Exception as e:
        print(f"âŒ æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        return

    # æ¨¡å‹è¯„ä¼°
    try:
        predictions, targets, embeddings = evaluate_model(model, eval_dataloader, device)

        if len(predictions['ipa']) == 0:
            print("âŒ æ¨¡å‹è¯„ä¼°æœªäº§ç”Ÿä»»ä½•é¢„æµ‹ç»“æœ")
            return

    except Exception as e:
        print(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
        return

    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    print("\n" + "=" * 50)
    print("ğŸ“Š æ€§èƒ½è¯„ä¼°ç»“æœ")
    print("=" * 50)

    # IPAæŒ‡æ ‡
    ipa_metrics = calculate_metrics(predictions['ipa'], targets['ipa'], 'IPA')

    # SQIæŒ‡æ ‡ï¼ˆå®é™…æ˜¯ååº¦ï¼‰
    sqi_metrics = calculate_metrics(predictions['sqi'], targets['sqi'], 'Skewness')

    # ç»˜åˆ¶é¢„æµ‹å›¾
    print(f"\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    try:
        plot_predictions(predictions['ipa'], targets['ipa'], 'IPA',
                         f"{model_dir_path}/ipa_predictions.png")

        plot_predictions(predictions['sqi'], targets['sqi'], 'Skewness',
                         f"{model_dir_path}/skewness_predictions.png")
    except Exception as e:
        print(f"âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")

    # åµŒå…¥å‘é‡åˆ†æ
    if len(embeddings) > 0:
        print(f"\nğŸ§¬ åµŒå…¥å‘é‡åˆ†æ:")
        print(f"   åµŒå…¥ç»´åº¦: {embeddings.shape[1]}")
        print(f"   åµŒå…¥å‘é‡èŒƒå›´: {embeddings.min():.3f} - {embeddings.max():.3f}")
        print(f"   åµŒå…¥å‘é‡å¹³å‡å€¼: {embeddings.mean():.3f}")
        print(f"   åµŒå…¥å‘é‡æ ‡å‡†å·®: {embeddings.std():.3f}")

        # ä¿å­˜è¯„ä¼°ç»“æœ
        eval_results = {
            'ipa_metrics': ipa_metrics,
            'skewness_metrics': sqi_metrics,
            'embedding_stats': {
                'shape': embeddings.shape,
                'mean': embeddings.mean(),
                'std': embeddings.std(),
                'min': embeddings.min(),
                'max': embeddings.max()
            },
            'num_samples': len(predictions['ipa'])
        }

        try:
            results_path = f"{model_dir_path}/evaluation_results.pkl"
            joblib.dump(eval_results, results_path)
            print(f"\nğŸ’¾ è¯„ä¼°ç»“æœä¿å­˜åˆ°: {results_path}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜è¯„ä¼°ç»“æœå¤±è´¥: {e}")

    # æ€»ç»“
    print(f"\n" + "=" * 50)
    print("ğŸ“‹ è¯„ä¼°æ€»ç»“")
    print("=" * 50)
    print(f"ğŸ¯ IPAé¢„æµ‹MAE: {ipa_metrics['mae']:.4f}")
    print(f"ğŸ¯ ååº¦é¢„æµ‹MAE: {sqi_metrics['mae']:.4f}")
    print(f"ğŸ“Š è¯„ä¼°æ ·æœ¬æ•°: {len(predictions['ipa'])}")
    print(f"ğŸ’¡ å»ºè®®ï¼šåŸºäºå½“å‰æ€§èƒ½ï¼Œæ¨¡å‹è®­ç»ƒæ•ˆæœè‰¯å¥½")

    # æ•°æ®è´¨é‡æŠ¥å‘Š
    print(f"\nğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š:")
    print(f"   IPA é¢„æµ‹èŒƒå›´: {min(predictions['ipa']):.3f} - {max(predictions['ipa']):.3f}")
    print(f"   IPA çœŸå®èŒƒå›´: {min(targets['ipa']):.3f} - {max(targets['ipa']):.3f}")
    print(f"   ååº¦é¢„æµ‹èŒƒå›´: {min(predictions['sqi']):.3f} - {max(predictions['sqi']):.3f}")
    print(f"   ååº¦çœŸå®èŒƒå›´: {min(targets['sqi']):.3f} - {max(targets['sqi']):.3f}")


if __name__ == "__main__":
    main()